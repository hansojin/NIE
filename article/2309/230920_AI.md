# 음식 이미지 올리니 조리법 쫙 …'멀티모달 AI' 급부상
## 빅테크, 이젠 차세대 AI 경쟁
## LLM 개발사와 격차 벌리기
## 다양한 형태 데이터 처리해
## 텍스트·이미지·음성 생성
## 구글, 1조 파라미터 '제미니'
## 오픈AI 'GPT-비전' 본격 대결
[음식 이미지 올리니 조리법 쫙 …'멀티모달 AI' 급부상 - 매일경제](https://n.news.naver.com/article/newspaper/009/0005188936?date=20230920)

---

![멀티모달](https://github.com/hansojin/NIE/assets/112622663/7b6b610a-85a8-4bc9-9e63-92a65b3442e3)

`구글과 오픈AI가 텍스트를 넘어 음성, 이미지, 영상 등 다양한 형태의 데이터를 분석하고 생성할 수 있는 이른바 '멀티모달(multimodal)' 인공지능(AI)을 곧 공개한다. 한국 기술기업이 텍스트 중심의 대규모언어모델(LLM) 개발에 집중하는 사이 미국 빅테크가 거대 자본을 앞세워 후발주자와 격차를 더 벌리려는 것이다.`

18일(현지시간) 미국 정보기술(IT) 전문매체 디인포메이션에 따르면 구글과 오픈AI는 각각 연내 '멀티모달 AI' 공개를 목표로 하고 있다. 프롬프터에 문장을 입력했을 때 문장만 생성하는 LLM과 달리 멀티모달 AI는 텍스트, 이미지, 음성, 영상 등을 제한 없이 모두 생성한다. 예를 들어 사용자가 음식 이미지를 업로드하면 해당 식재료 내용과 조리법을 생성하고, 숫자가 포함된 문서를 올리면 즉석에서 그래프나 도표를 보여주는 방식이다.

`멀티모달 출시를 가장 서두르는 빅테크는 구글이다. 구글은 멀티모달 엔진 '제미니(Gemini)'에 대한 개발을 마치고 일부 기업과 테스트하고 있다.` **제미니는 인간 두뇌의 시냅스에 해당하는 파라미터(매개변수)가 약 1조개에 달하는 것으로 알려졌다. 오픈AI가 내놓은 최신 버전 GPT-4의 파라미터가 5000억개로 추산되는 것에 비하면 2배가량 많다.**

업계에서는 제미니가 유튜브 영상의 인터넷주소(URL)를 입력하면 자동으로 스크립트를 생성하고 분석해줄 것으로 기대한다. 다만 무료는 아닐 것으로 보인다. **월 구독료는 30달러로 추정된다.** `그동안 구글은 오픈AI와 마이크로소프트(MS)를 꺾고자 AI 조직을 통폐합했다. AI 계열인 딥마인드와 구글 내 AI 조직인 브레인을 통폐합해 '구글 딥마인드'로 변경했고, 수장에는 '알파고' 주역인 데미스 허사비스를 앉혔다. 특히 세르게이 브린 구글 창업자가 이를 적극 지원하는 것으로 알려졌다.`

이 같은 소식에 오픈AI가 반격에 나섰다. 오픈AI는 올해 3월 GPT-4를 내놓으면서 멀티모달 AI의 초기 버전을 시연했다. 요리 이미지를 올리면 조리법을 생성하고 식재료를 분석했지만, 해당 기능은 데모 시연에 그쳤다. 디인포메이션은 "오픈AI가 'GPT-비전'으로 불리는 기술을 곧 공개할 것으로 보인다"며 "이와 함께 GPT-비전보다 더 강력한 '고비(Gobi)'라는 프로젝트를 운영하고 있어 주목된다"고 전했다.

오픈AI는 LLM인 GPT-4와 이미지 AI인 달리(DALL·E)를 각각 선보인 바 있다. `하지만 '고비'는 처음부터 멀티모달 AI로 개발되고 있어 LLM과 이미지 AI를 합한 것과 차원이 다를 것이라는 평가가 나온다.`

오픈AI는 인재 채용에도 사활을 걸고 있다. **오픈AI 홈페이지에 따르면 현재 최대 연봉 37만달러(약 4억9000만원)를 걸고 멀티모달 전문가를 채용 중이다.**

업계에서는 구글과 오픈AI 간 멀티모달 AI 대결을 2라운드로 보고 있다. 디인포메이션은 "구글이 검색엔진과 유튜브를 보유하고 있어 멀티모달을 내놓으면 비즈니스 측면에서도 상당히 유리할 것으로 전망된다"며 "AI 업계에선 이를 제2의 아이폰 대 안드로이드폰 대결로 보고 있다"고 설명했다. `다른 기업이 진입할 틈도 없이 AI 생태계가 이원화될 것이라는 분석이다.`

`시장조사기관 ABI리서치에 따르면 멀티모달 AI가 확산되면 자율주행, 로봇, 스마트홈 분야에서 획기적인 변화가 일어날 가능성이 크다.` 예를 들어 로봇에 입력된 이미지와 영상을 분석해 소비자가 이해하기 쉬운 텍스트로 전달할 수 있다. **포천비즈니스인사이트에 따르면 글로벌 AI 시장 규모는 2022년 4280억달러에서 2030년에는 2조251억달러로 커질 것으로 전망된다.**

`다만 멀티모달은 다양한 데이터를 학습해 악용에 대한 염려가 더 크다.` 예를 들어 특정 인물 사진을 올려 분석을 요청한 뒤 이를 안면인식 AI를 해킹하는 데 악용할 수 있다. 오픈AI는 이 같은 이유로 GPT-비전 공개를 미뤄왔는데, 구글이 선수를 치면서 경쟁이 가속화될 전망이다. `국내에선 LG가 이미지 문장을 양방향 생성하는 엑사원을 내놓은 바 있다.`

---

### [용어정리]
* 멀티모달 AI
    * 텍스트, 이미지, 영상, 음성 등 다양한 데이터 모달리티를 함께 고려하여 서로의 관계성을 학습 및 표현하는 기술
    * 예를 들어, 이미지로 텍스트 검색을 하거나 텍스트에서 이미지를 검색, 혹은 이미지와 텍스트를 같이 이해하는 멀티모달 검색이 가능함
    * 최근에는 이미지를 보고 텍스트를 생성하거나 텍스트를 기반으로 이미지를 생성하는 다양한 활용 사례도 존재
* 유니모달
    * 기존의 AI는 텍스트나 자연어를 이해하는 데 중점을 둠
        * 인류가 만든 가장 많은 데이터는 바로 글로 남겨진 텍스트였고, 사람이 주고받는 언어를 이해하는 자연어 분석(NLP)이 전제되어야, 명제와 추론을 할 수 있다고 본 것
    * 데이터 처리나 통계, 텍스트를 검색해서 보여주는 것은 가능하지만, 인간과 유사한 방식의 사고는 할 수가 없었음
* LLM
    * Large Language Model _ 대용량의 언어 모델을 의미
    * LM(언어 모델, Language Model)은 인간의 언어를 이해하고 생성하도록 훈련된 일종의 인공지능 모델로 주어진 언어 내에서 패턴이나 구조, 관계를 학습하여 텍스트 번역과 같은 좁은 AI 작업에서 주로 활용
    * LLM은 딥 러닝 알고리즘과 통계 모델링을 통해 자연어 처리(Natural Language Processing, NLP) 작업을 수행하는 데에 사용
    * 사전에 대규모의 언어 데이터를 학습하여 문장 구조나 문법, 의미 등을 이해하고 생성할 수 있음

---

### [본문의 근거] 
* 제미니(구글)는 인간 두뇌의 시냅스에 해당하는 파라미터(매개변수)가 약 1조개에 달하는 것으로 알려졌다. 오픈AI가 내놓은 최신 버전 GPT-4의 파라미터가 5000억개로 추산되는 것에 비하면 2배가량 많다.
* (제미니의) 월 구독료는 30달러로 추정된다.
* 오픈AI 홈페이지에 따르면 현재 최대 연봉 37만달러(약 4억9000만원)를 걸고 멀티모달 전문가를 채용 중이다.
* 포천비즈니스인사이트에 따르면 글로벌 AI 시장 규모는 2022년 4280억달러에서 2030년에는 2조251억달러로 커질 것으로 전망된다.

---

### 추가 조사할 내용 / 결과 
#### 기사의 근거를 통해 바뀐 수치는 무엇인가?
* 구글 _ AI 계열인 딥마인드와 구글 내 AI 조직인 브레인을 통폐합한 '구글 딥마인드'
    * 주요 목표는 머신러닝과 신경과학을 기반으로 인간의 지능을 분석, 구현하는 것
    * 인공물에 인공 지능을 탑재하는 것 뿐만 아니라, 더 나아가서 인간 지능의 궁극적인 이해를 목표로 두고 있음
    * 인공지능 바둑 프로그램인 알파고(AlphaGo)를 개발
        *독자적인 심층 인공지능 기술인 ‘심층 큐 네트워크’(Deep Q-network) 사용
* 오픈AI _ LLM인 GPT-4, 이미지 AI인 달리(DALL·E)
    * GPT-4
        * ChatGPT의 여러가지 부분에서 진화를 했음
        * AI 모델의 파라미터 수가 커졌으며, 모델의 최대 입력 토큰 수도 기존 4,096개에서 32,768개로 늘어났음. 또 하나의 큰 특징은 이미지를 보고 이해할 수 있는 멀티모달 기능이 추가되었다는 점
        * 이로써 AGI(Artificial General Intelligence)를 위해 앞으로도 점점 학습하는 모델과 데이터셋은 커질 것이고, 기존의 언어만 이해하던 모델에서 이미지, 영상, 음성 등의 다양한 모달리티를 이해할 수 있는 모델로 진화할 것이 자연스럽게 예상
    * 달리(DALL·E) 
        * 텍스트로 고해상도 이미지를 생성하는 AI 신경망 시스템 
        * 수정하려는 이미지에 대해 자연어로 수정 사항을 지정해 편집 가능
        * 유해한 이미지의 생성을 제한하는 데이터 세트와 필터를 적용
        * 디지털 이미지를 만들고 편집할 때 새로운 아이디어들을 제공
* NLP vs LLM
    * NLP (Natural Language Processing)
        * 인간의 언어를 이해하고 처리하는 데 초점을 맞춘 인공지능 분야
        * 컴퓨터가 자연어 텍스트를 이해하고 분석하는 기술을 개발하는 것을 목표
        * 문장 구문 분석, 텍스트 분류, 기계 번역, 질의 응답 시스템, 감정 분석 등과 같은 다양한 작업에 활용
    * LLM
        * 큰 데이터셋을 사용하여 훈련된 대용량의 언어 모델
        * 딥 러닝 기술과 통계 모델링을 사용하여 자연어 처리 작업을 수행
    * 즉, NLP는 자연어 처리 분야 전반을 아우르는 개념이며, 텍스트를 이해하고 처리하는 기술에 초점을 두고 LLM은 NLP의 한 부분으로, 대량의 언어 데이터를 바탕으로 학습된 언어 모델을 사용하여 특정 NLP 작업을 수행하는데 초점을 둠
    * NLP는 더 넓은 의미의 개념이며, LLM은 그 안에서 특정한 접근 방식과 모델을 가리키는 한 가지 형태임
---

#### 적용할점 (현직자에게 할 질문)
* 멀티모달 AI가 확산되면 발생할 수 있는 가장 큰 변화로는 무엇이 있을지. 
* 사실 AI 사용에 있어서 아직까지도  윤리, 규제, 사회적 영향 등의 다양한 측면에서 문제가 되는 부분이 많은데 개발을 하는데에 있어서 이런 측면들도 고려를 하고 있는건지

--- 
#### 연관기사 링크

[오픈AI vs 구글, 텍스트·이미지 멀티모달 LLM 선점 레이스 - 디지털 투데이](http://www.digitaltoday.co.kr/news/articleView.html?idxno=488524)

[챗GPT다음?... 텍스트·이미지·음성 연결하는 '멀티모달 AI' 뭐길래 - 주간조선](http://weekly.chosun.com/news/articleView.html?idxno=28553)

[챗GPT, 그림에도 눈 뜨자…AI전쟁 '멀티모달'로 확전- 서울경제](https://www.sedaily.com/NewsView/29N6E8E191)
