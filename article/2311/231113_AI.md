# AI 가짜뉴스 집어낸다는 워터마크, 아직은 뻥뻥 뚫린다
## 창과 방패처럼…쫓고 쫓기는 'AI 탐지 전쟁'
## 정부, AI 워터마크 법제화 속도
## 주요 28개국도 도입 논의했지만
## 현재로선 로고 잘라내면 그만
## 해외선 기계만 아는 코드 심고
## 콘텐츠 학습 못하게 막는 기술도
[AI 가짜뉴스 집어낸다는 워터마크, 아직은 뻥뻥 뚫린다 - 한국경제](https://n.news.naver.com/article/newspaper/015/0004913098?date=20231113)

---

`생성형 인공지능(AI)으로 만든 사진, 영상 등으로 인한 사회적 부작용이 커지면서 각국 정부와 빅테크를 중심으로 AI 생성물을 구분할 수 있는 ‘워터마크’ 도입 움직임이 빨라지고 있다.` 한국 정부도 워터마크 법제화를 검토 중이다. 백신을 피하기 위해 바이러스가 진화하고, 이에 맞춰 백신이 개량되는 것처럼 AI 생성물을 둘러싼 ‘창과 방패의 싸움’의 막이 올랐다는 분석이다.

![waterMark](https://github.com/hansojin/NIE/assets/112622663/808c106c-a48b-4bf4-a1b7-16a304e08c11)

#### 정부, 워터마크 법제화 검토

12일 정보기술(IT)업계에 따르면 과학기술정보통신부는 AI 생성물에 대한 표시 도입 등 AI 위험성 완화 방안을 이달부터 검토할 계획이다. 국회와 함께 법제화 방안을 논의하는 동시에 사업자에게 이용자 보호를 위해 가시적 워터마크 도입을 권고하고 나섰다. 최근 영국에서 열린 주요 28개국 ‘AI 정상회의’에서도 AI의 부작용을 막기 위해 워터마크를 도입하는 논의 등이 이뤄졌다.

`정부가 권고한 가시적 워터마크는 단어 그대로 사람이 눈으로 볼 수 있는 워터마크를 디지털 콘텐츠에 삽입하는 것을 의미한다.` 기존에도 저작권이 있는 이미지 위에 도용을 막기 위해 회사 이름이나 로고를 넣는 방식의 워터마크가 쓰였다. 오픈AI의 달리(Dall-e)나 SK텔레콤의 에이닷 포토 등에서 이미지를 만들면 한쪽 구석에 AI가 제작했다는 사실을 알려주는 문구나 서비스 로고 등을 볼 수 있다.

`이 방법은 만들기 쉽고 이용자도 AI 생성 여부를 쉽게 확인할 수 있다. 하지만 무력화하는 것도 간단하다. 구석에 로고가 있을 경우 이미지 일부를 잘라내면 되고, 화면 위에 이미지를 덮더라도 간단한 프로그램으로 삭제할 수 있다.`

#### “부작용 막을 최소한의 안전장치”

`눈에 보이지 않는 비가시적 워터마크에 대한 연구도 활발하다. 겉으로는 알 수 없지만, 기계가 알 수 있는 코드를 삽입하는 방식이다.` `구글이 지난 8월 공개한 ‘신스 아이디(Synth ID)’는 AI만 인식할 수 있는 픽셀 단위의 흔적을 남겨 AI 생성물 여부를 확인할 수 있다.`

`이미지나 영상은 물론 생성 AI가 만든 텍스트에 대한 워터마크도 연구되고 있다. AI가 텍스트를 만들 때 특정 단어의 빈도나 배열하는 규칙을 정해 AI 생성물을 알아채는 방식이다. 하지만 약간의 수정만으로도 무력화할 수 있어 이미지, 영상 등과 비교해 실용성이 떨어진다. 실제로 오픈AI는 올해 초 챗GPT가 만든 텍스트를 구분하는 AI 서비스를 내놨지만 낮은 탐지 확률을 개선하지 못하고 지난 7월 서비스를 중단했다.`

`최근에는 AI가 자신의 콘텐츠를 학습할 수 없도록 방지하는 기술도 나왔다.` 미국 시카고대 연구진이 최근 공개한 ‘나이트셰이드’는 이미지에 ‘오염된 학습 데이터’를 주입할 수 있다. 강아지가 그려진 사진에 고양이라는 데이터를 넣는 식이다.

이런 이미지를 학습한 AI에 강아지를 그려달라고 하면 고양이와 강아지가 섞인 이미지를 만들게 된다. 무단으로 이미지를 가져다 쓰면 AI의 학습 알고리즘 전체가 망가진다.

`업계에선 워터마크가 생성 AI의 부작용을 원천 방지할 수는 없을 것으로 보고 있다.` 바이러스와 백신의 관계처럼 워터마크를 무력화하기 위한 기술이 끊임없이 나올 것이기 때문이다. 한 업계 관계자는 “문에 자물쇠를 채우더라도 도둑을 완전히 막을 수 없지만, 대부분 범죄는 방지할 수 있다”며 “AI의 부작용을 막는 최소한의 안전장치 역할을 할 것”이라고 말했다.


---

### 추가 조사할 내용 / 결과 
#### 기사의 근거를 통해 바뀐 수치는 무엇인가?

* 신스ID(SynthID)
    * 구글 클라우드 컨퍼런스에서 AI 생성 이미지에 대한 워터마크·식별도구 
    * 눈에 보이는 워터마크 대신 이미지를 구성하는 픽셀마다 AI로 만들었다는 흔적을 남김
    * 원본 품질도 영향을 주지 않으면서 이미지에 눈으로 식별할 수 없는 투명한 워터마크를 덧입히는 방식
    * 다만 신스ID 자체도 AI로 만들어진 기술이기 때문에 워터마크가 있는 이미지를 완벽하게 식별하는 것은 불가능
        * 대신 워터마크가 존재할 가능성이 있는 이미지와 워터마크가 거의 확실히 존재하는 이미지는 구분할 수 있음
        * 이를 통해 가짜 가능성이 있는 이미지를 정밀하게 식별해 ‘100% 진짜 이미지’를 가려낼 수 있다는 것
    * 현재 구글 클라우드의 생성 AI 플랫폼인 ‘버텍스AI’에서만 사용할 수 있으며, 구글의 이미지 생성 모델 '이메진(Imagen)'으로 생성된 합성 이미지에 워터마크를 입히고 이미지에서 워터마크를 스캔해 낼 수 있음
        * 달리나 미드저니, 스테이블 디퓨전 등 다른 AI 생성 이미지를 구별하는 것은 불가능
        * 그러나 이 기술이 범용화되면 AI 기반 '가짜 뉴스' 등을 방지하는 데 도움이 될 전망
    * 디지털 콘텐츠를 식별하는 광범위한 접근 방식에 기여
        * 오디오, 비디오, 텍스트 등의 다른 생성 AI 모델에도 적용할 수 있음

---

#### [Claire L. Evans 리뷰](https://www.technologyreview.kr/why-watermarking-ai-generated-content-wont-guarantee-trust-online/)

* 워터마크 자체가 변조될 수 있는가?
    * 아이러니하게도 콘텐츠의 출처와 조작 방법을 파악하는 데 도움이 된다고 여겨지는 기술적 신호 자체가 때로는 조작될 수도 있다. 물론 조작이 쉽지는 않지만, 가시적 워터마크나 비가시적 워터마크 모두 제거되거나 변경될 수 있기 때문에 AI 합성 이미지를 식별하는 장치로는 유용하지 않을 수 있다. 특히 콘텐츠 유형에 따라서 워터마크 조작의 용이성도 달라질 수 있다.
* 콘텐츠 유형과 상관없이 워터마크의 지속성은 동일한가?
    * 비가시적 워터마크는 생성형 AI(generative AI)에 대한 광범위한 해결책처럼 홍보된다. 그러나 이러한 내장형 워터마크는 시청각 콘텐츠보다 텍스트 콘텐츠에서 훨씬 더 쉽게 조작될 수 있다. 위에서 언급한 백악관의 요약 문서에서는 모든 유형의 AI에 워터마크를 적용할 것이라고 했지만, 전문을 살펴보면 기업들이 시청각 콘텐츠에 대한 정보공개 표시만 약속한 것으로 명시되어 있다. 이는 아마도 콘텐츠 유형에 따른 이러한 워터마크 조작의 용이성 차이 때문일 것이다. 따라서 AI 정책 수립을 위해서는 비가시적 워터마크 삽입 같은 공개 기술의 지속성과 강인성이 콘텐츠 유형에 따라 어떻게 달라지는지 구체적으로 파악해야 한다. 예를 들어 이미지에는 유용하지만, 텍스트에는 쓸모없는 공개 방식이 있을 수도 있다.
* 이러한 비가시적 신호는 누가 감지할 수 있을까?
    * 비가시적 워터마크 삽입에 동의한다면, AI 분야에서 이러한 워터마크를 감지하고 이를 기반으로 권위 있는 주장을 할 수 있는 주체가 누가 되어야 하는지에 결정해야 한다. 콘텐츠가 AI로 생성되었는지, 더 나아가서 콘텐츠에 오해의 소지가 있지 않은지는 누가 결정할 수 있을까? 모든 사람이 워터마크를 감지할 수 있다면, 악의적인 사용자가 워터마크를 오용하는 일이 늘어날 수 있다. 그렇다고 비가시적 워터마크 감지를 제한한다면, 특히 거대 AI 기업들이 이를 주도한다면, 개방성이 저하될 뿐만 아니라 기술에 대한 통제도 심화될 수 있다. 관리 방법에 대한 고민 없이 이러한 공개 방식을 사용하게 되면 비효율적이고 신뢰할 수 없는 방식으로 변질될 수 있다. 게다가 해당 기술이 널리 채택되지 않으면 악의적인 행위자들이 비가시적 워터마크가 없는 오픈소스 기술을 사용해서 유해하고 오해의 소지가 있는 콘텐츠를 만들 수도 있다.
* 워터마크는 개인정보를 보호하는가?
    * 인권 및 기술 단체인 위트니스의 주요 연구 결과를 보면, 오랜 시간에 걸쳐 콘텐츠와 함께 이동하는 추적 시스템은 콘텐츠 제작자의 개인정보 보호 문제를 초래할 수 있다. AI 분야에서는 워터마크 등 공개 기술이 콘텐츠 제작자의 식별 정보(identifying information)를 포함하지 않도록 설계해야 한다. 이러한 정보가 콘텐츠 제작자를 위험에 빠뜨릴 수도 있기 때문이다. 예를 들어 인권 활동가가 인권 침해 사례를 찍은 사진에 워터마크 형태의 식별 정보가 삽입되었다면, 이 활동가는 권위주의 정부의 쉬운 표적이 될 수 있을 것이다. 또한 워터마크가 활동가의 신원을 드러낼 수 있다는 사실만으로도 사람들의 표현과 발언의 자유가 위축될 수 있다. 따라서 정책입안자들은 콘텐츠 제작자의 개인정보를 보호하는 동시에, 명확한 지침을 제공해 유용하고 실용적인 세부 정보를 포함하는 정보공개 방식을 설계할 수 있도록 해야 한다. 
* 가시적 공개 방식이 생성형 AI의 역할을 이해하는 데 도움을 주는가?
    * 비가시적 워터마크는 기술적으로 지속성이 강하고 개인정보를 보호할 수 있지만, 이용자가 콘텐츠를 이해하는 데에는 도움이 되지 않을 수 있다. 가시적 워터마크 같은 직접적인 정보공개 방식은 더 강한 투명성을 제공한다는 직관적인 장점이 있지만 반드시 의도한 효과를 내는 것은 아니며, 콘텐츠의 진실성에 대해 아무것도 보여주지 않을 때도 편향적이고 징벌적인 것으로 인식될 수 있다. 또한 사용자가 직접적으로 공개된 정보를 잘못 해석할 가능성도 있다. 필자가 2021년에 진행한 연구에서 한 참여자는 트위터의 ‘조작된 미디어(manipulated media)’라는 라벨을 보고 특정 동영상의 내용이 오해를 불러일으키도록 편집됐다는 의미가 아니라, ‘미디어(media)’라는 기관이 자신을 조종(manipulating)하고 있다는 의미로 잘못 해석하기도 했다. 다양한 사용자 경험 설계가 콘텐츠 정보공개에 대한 사용자의 해석에 어떤 영향을 미치는지에 대한 연구가 진행되고 있지만, 그러한 연구의 대부분은 빅테크 기업에서 진행되고 있으며 선거와 같은 특정 상황에 초점이 맞춰져 있다. 투명성 개선을 위한 효과적인 정책을 수립하려면 AI 생성 콘텐츠에 라벨을 붙이는 행위에만 집중하는 것이 아니라, 직접적인 정보공개와 사용자 경험의 효과성을 반드시 연구해야 한다.
* AI 생성 콘텐츠에 워터마크를 삽입하는 것으로 ‘진짜’ 콘텐츠에 대한 신뢰가 떨어질 수 있을까?
    * 아마 사회적으로 가장 평가하기 어려운 질문은 직접적인 정보공개가 정보에 대한 태도에 어떤 영향을 미칠지, 그리고 잠재적으로 ‘진짜’ 콘텐츠에 대한 신뢰를 떨어뜨릴지 여부일 것이다. AI 관련 조직과 소셜미디어 플랫폼들이 (오해의 소지가 있는 주장이나 유해한 내용에 대한 판단을 피하기 위한 제한적이지만 이해하기 쉬운 방법으로) 콘텐츠가 AI로 생성됐거나 수정됐다는 사실을 표시하기만 한다면, 이러한 조치는 우리의 온라인 콘텐츠 인식 방식에 어떤 영향을 줄까?
    * 정보공개를 통해 미디어 리터러시(media literacy, 또는 ‘미디어 문해력’)를 함양하려는 시도에는 의미가 있다. 그러나 기술 기업 안팎의 정책팀에서 일하는 사람들은 모든 AI 생성 콘텐츠에 라벨을 붙이려는 성급한 행위가 ‘거짓말쟁이의 배당금(liar’s dividend)*’ 현상으로 이어질 수도 있다고 우려하고 있다. [*편집자 주: 자기에게 불리한 내용은 모두 ‘가짜 뉴스’라고 우기는 것]. 즉 ‘잠재적으로 모든 콘텐츠를 AI 생성 콘텐츠로 간주하면서, AI로 생성하지 않은 ‘진짜’ 콘텐츠에 대한 신뢰까지 약화되는 현상’이 발생할 수 있다는 것이다. 이러한 우려로 인해 위험성이 낮아 보이는 상황에서도 AI 활용 여부를 공개해야 하는지에 대한 논란이 있다(예: AI 기술을 사용하는 아이폰의 인물 사진 모드 또는 백악관 문서에 언급된 음성 비서(voice assistant) 등). 이 문제를 해결하려면 시간이 지남에 따라 사회가 정보에 대해 어떤 태도를 보이는지 측정하고 AI 개입 여부를 언제 공개하는 것이 합당한지 결정하기 위해 이 분야의 모두가 함께 노력해야 할 것이다. 무엇보다도, 우리가 진정으로 중요하게 생각하는 것, 즉 콘텐츠의 주장이 진실인지 거짓인지 대변하는 방법으로 콘텐츠 제작 방법을 단순히 설명하는 가시적 정보공개 방식(예: 콘텐츠가 AI로 생성 또는 편집됐다고 표시)이 가져올 수 있는 영향에 대해 평가해야 한다.
    * 워터마크나 기타 공개 기술이 제기하는 문제에 무대책으로 일관하거나, 이를 투명성을 제한하는 것이라는 핑계로 삼아서는 안 된다. 오히려 그러한 문제들을 바탕으로 기업, 정책 입안자, 기타 관련자들이 함께 정의를 내리고 다양한 정보공개 방식에 수반되는 장단점을 어떻게 평가할지 결정해야 한다. 그래야만 생성형 AI 정책이 콘텐츠의 조작 여부와 사실을 구분하는 데 적절한 도움을 줄 수 있을 것이다.

--- 

#### 연관기사 링크

[구글, AI 생성 이미지에 '투명 워터마크' 삽입하는 기술 공개 - AI타임즈](https://www.aitimes.com/news/articleView.html?idxno=153282)

[워터마크의 한계, AI 생성 콘텐츠 표시 방법으로 충분치 않은 이유 - MIT technology review](https://www.technologyreview.kr/why-watermarking-ai-generated-content-wont-guarantee-trust-online/)

[AI 생성 이미지 '워터마크' 붙인다…국내 플랫폼도 '시동' - 지디넷코리아](https://zdnet.co.kr/view/?no=20230830155102)
